import os

os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
import torch
import torch.nn as nn
import torch.nn.functional as F
from einops import rearrange
import argparse
from scipy.signal import firwin, filtfilt
from scipy.signal import firwin, lfilter, filtfilt
from scipy.stats import pearsonr
from sklearn.ensemble import RandomForestClassifier
import os
from torch.utils.data import DataLoader, TensorDataset
from scipy.ndimage import gaussian_filter1d
from mne.filter import resample
import math
import librosa
from sklearn.preprocessing import StandardScaler
from scipy.signal import welch, csd
from sklearn.manifold import TSNE
# from torchdiffeq import odeint
gpus = [0]
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'
os.environ["CUDA_VISIBLE_DEVICES"] = ','.join(map(str, gpus))
import numpy as np
import math
import glob
from scipy.signal import savgol_filter
from scipy.signal import medfilt
import random
import itertools
from scipy.signal import butter, filtfilt
from scipy.signal import hilbert
import dtcwt
from dtcwt import Pyramid
from dtcwt.numpy import Transform1d
from scipy.fft import fft, ifft
# from scipy.signal import resample
from joblib import Parallel, delayed
import numpy as np
import datetime
import time
import datetime
import sys
import scipy.io
from sklearn.model_selection import train_test_split
import torchvision.transforms as transforms
from torchvision.utils import save_image, make_grid
from scipy.signal import cheby1, filtfilt
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from sklearn.metrics import confusion_matrix, cohen_kappa_score, recall_score, precision_score, f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.decomposition import PCA
import seaborn as sns
import mne
from collections import Counter
from torch.utils.data import DataLoader
from torch.autograd import Variable
from torchsummary import summary
import torch.autograd as autograd
from torch.nn.utils import weight_norm
from torchvision.models import vgg19
import scipy.io as spio
import torch.nn as nn
import torch.nn.functional as F
import torch
import torch.nn.init as init
from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef
from torch.utils.data import DataLoader, WeightedRandomSampler
from torch.utils.data import Dataset
from PIL import Image
import torchvision.transforms as transforms
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score, cohen_kappa_score
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
from sklearn.utils import shuffle
from torch import nn
import pickle
from torch import Tensor
from PIL import Image
from torchvision.transforms import Compose, Resize, ToTensor
from einops import rearrange, reduce, repeat
from einops.layers.torch import Rearrange, Reduce
# from common_spatial_pattern import csp
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import StratifiedKFold
# from torch.utils.tensorboard import SummaryWriter
from torch.backends import cudnn
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
# from tensorflow.keras.utils import to_categorical
from joblib import Parallel, delayed
import gc
from sklearn.model_selection import KFold

gc.collect()
import psutil

print(f"Available Memory: {psutil.virtual_memory().available / (1024 ** 2)} MB")
print(f"Available Memory: {psutil.virtual_memory().available / (1024 ** 3):.2f} GB")

cudnn.benchmark = False
cudnn.deterministic = True


def load_data(path, file_name):
    file_path = os.path.join(path, file_name)
    df = pd.read_pickle(file_path)
    return df


def extract_features_and_labels(df, label_col='condition', epoch_col='epoch', time_col='time'):
    # æ˜¾å¼å®šä¹‰ç”µæé€šé“åˆ—åï¼ˆæ ¹æ®æ‚¨çš„å®é™…åˆ—åï¼‰
    channel_columns = [
        # Group 1 â€“ Broca's & Wernicke's Area
        'FT8', 'T7', 'P3', 'C3', 'C5', 'C4', 'FC6', 'F5', 'F3', 'FC3', 'FC5',
        # Group 2 â€“ Motor Cortex
        'C3', 'C5', 'C1', 'CZ', 'C2', 'C4', 'FC1', 'FCZ', 'FC2', 'FC6', 'FC4',
        # Group 3 â€“ Frontal Lobe
        'F1', 'FZ', 'F2', 'F4', 'F6', 'FCZ', 'FC2', 'FPZ', 'FP2', 'AF3', 'AF4',
        # Group 4 â€“ Parietal & Occipital Lobes
        'P1', 'P2', 'P4', 'PZ', 'POZ', 'PO4', 'PO6', 'CP3', 'CP5', 'CP1', 'CPZ',
        # Group 5 â€“ Insular Approx. Area
        'F8', 'T8', 'TP8', 'P8'
    ]

    # æ¸…ç†æ ‡ç­¾æ ¼å¼ï¼ˆç§»é™¤æ–œæ ï¼‰
    df[label_col] = df[label_col].str.replace('/', '')

    # å®šä¹‰ event_id æ˜ å°„ï¼ˆæ ¹æ®æ¸…ç†åçš„æ ‡ç­¾ï¼‰
    event_id = {
        'iy': 0,
        'uw': 1,
        'piy': 2,
        'tiy': 3,
        'diy': 4,
        'm': 5,
        'n': 6,
        'pat': 7,
        'pot': 8,
        'knew': 9,
        'gnaw': 10
    }

    X, y = [], []

    # æŒ‰epochåˆ†ç»„
    df_grouped = df.groupby(epoch_col)

    for epoch, group in df_grouped:
        # éªŒè¯æ ‡ç­¾å”¯ä¸€æ€§
        labels = group[label_col].unique()
        if len(labels) != 1:
            print(f"Epoch {epoch} å­˜åœ¨å¤šä¸ªæ ‡ç­¾: {labels}ï¼Œå·²è·³è¿‡")
            continue
        label = labels[0]

        # æ£€æŸ¥æ ‡ç­¾æ˜¯å¦æœ‰æ•ˆ
        if label not in event_id:
            print(f"Epoch {epoch} çš„æ ‡ç­¾ {label} æœªå®šä¹‰ï¼Œå·²è·³è¿‡")
            continue

        # æå–ç‰¹å¾ï¼ˆæ˜¾å¼é€‰æ‹©ç”µæé€šé“ï¼‰
        features = group[channel_columns].values.T  # (62, T)
        X.append(features)
        y.append(event_id[label])

        # è°ƒè¯•ä¿¡æ¯
        # print(f"Epoch {epoch} ç‰¹å¾å½¢çŠ¶: {features.shape}, æ ‡ç­¾: {label}")

    X = np.array(X)
    y = np.array(y)

    print(f"ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {X.shape}")
    print(f"æ ‡ç­¾å½¢çŠ¶: {y.shape}")
    return X, y


def augment_data_eeg_minimal(data, noise_level=0.3, max_shift=15):
    """
    å¯¹ EEG æ•°æ® (B, C, T) è¿›è¡Œç®€åŒ–å¢å¼ºï¼ˆåŠ å™ª + æ—¶é—´å¹³ç§»ï¼‰ã€‚

    å‚æ•°:
    - data: ndarray, EEG ä¿¡å·ï¼Œå½¢çŠ¶ä¸º (n_trials, n_channels, n_samples)
    - noise_level: float, å™ªå£°æ ‡å‡†å·®
    - max_shift: int, æœ€å¤§æ—¶é—´å¹³ç§»é‡ï¼ˆå‘å‰æˆ–å‘åï¼‰

    è¿”å›:
    - augmented_data: ndarray, å¢å¼ºåçš„ EEG æ•°æ®ï¼Œå½¢çŠ¶ç›¸åŒ (B, C, T)
    """
    B, C, T = data.shape
    augmented_data = np.zeros_like(data, dtype=np.float32)

    for i in range(B):
        for c in range(C):
            signal = data[i, c]

            # Step 1: åŠ é«˜æ–¯å™ªå£°
            noise = np.random.normal(0, noise_level, size=T)
            signal_noisy = signal + noise

            # Step 2: æ—¶é—´å¹³ç§»
            shift = np.random.randint(-max_shift, max_shift + 1)
            signal_shifted = np.roll(signal_noisy, shift)

            # è¾¹ç¼˜è¡¥0
            if shift > 0:
                signal_shifted[:shift] = 0
            elif shift < 0:
                signal_shifted[shift:] = 0

            augmented_data[i, c] = signal_shifted

    return augmented_data


def augment_data_eeg_bandwise(
        data,
        beta_noise_level=0.1,
        env_noise_level=0.3,
        max_shift=15,
        mask_prob=0.3,
        mask_length=20
):
    """
    é’ˆå¯¹ä¸åŒé¢‘æ®µç‰¹å¾ç±»å‹çš„ EEG å¢å¼ºï¼š
    - band 0: beta åŸå§‹ EEGï¼ˆä¿ç•™ç›¸ä½ï¼‰
    - band 1: low-gamma envelope
    - band 2: high-gamma envelope

    è¿”å›ï¼š
    - shape (B, 3, C, T)
    """
    B, bands, C, T = data.shape
    assert bands == 3, "éœ€è¦è¾“å…¥ 6 ä¸ªé¢‘æ®µï¼ˆbeta, low-gamma, high-gammaï¼‰"

    augmented = np.zeros_like(data, dtype=np.float32)

    for b in range(B):
        for band in range(bands):
            for c in range(C):
                signal = data[b, band, c].copy()

                # è®¾ç½®å½“å‰é¢‘æ®µçš„å‚æ•°
                if band == 0:
                    noise_level = beta_noise_level
                    apply_freq_dropout = False
                else:
                    noise_level = env_noise_level
                    apply_freq_dropout = False  # envelope ç¦æ­¢é¢‘è°± dropout

                # 1. åŠ å™ªå£°
                noise = np.random.normal(0, noise_level, size=T)
                signal += noise

                # 2. æ—¶é—´å¹³ç§»
                shift = np.random.randint(-max_shift, max_shift + 1)
                signal = np.roll(signal, shift)
                if shift > 0:
                    signal[:shift] = 0
                elif shift < 0:
                    signal[shift:] = 0

                # 3. é®æŒ¡
                if np.random.rand() < mask_prob and T > mask_length:
                    start = np.random.randint(0, T - mask_length)
                    signal[start:start + mask_length] = 0

                # 4.ï¼ˆå¯é€‰ï¼‰é¢‘è°± dropoutï¼ˆä»…é™ beta ä½¿ç”¨ï¼‰
                if apply_freq_dropout:
                    spectrum = fft(signal)
                    num_freq = len(spectrum) // 2
                    drop_len = int(num_freq * 0.2)
                    drop_start = np.random.randint(1, num_freq - drop_len)
                    spectrum[drop_start:drop_start + drop_len] = 0
                    spectrum[-(drop_start + drop_len):-drop_start] = 0
                    signal = np.real(ifft(spectrum))

                augmented[b, band, c] = signal

    return augmented


def mix_and_expand_data(train_x, train_y, augmentation_function, augment_ratio=0.3):
    """
    æ··åˆå’Œæ‰©å±•æ•°æ®
    """
    total_samples = len(train_x)
    num_augmented = int(total_samples * augment_ratio)

    # éšæœºé€‰æ‹©éœ€è¦å¢å¼ºçš„æ ·æœ¬ç´¢å¼•
    indices_to_augment = np.random.choice(total_samples, size=num_augmented, replace=False)

    # æå–éœ€è¦å¢å¼ºçš„æ•°æ®
    x_to_augment = train_x[indices_to_augment]
    y_to_augment = train_y[indices_to_augment]

    # å¯¹é€‰æ‹©çš„æ•°æ®è¿›è¡Œå¢å¼º
    x_augmented = augmentation_function(x_to_augment)
    y_augmented = np.copy(y_to_augment)  # æ ‡ç­¾ä¿æŒä¸€è‡´

    # åˆå¹¶åŸå§‹æ•°æ®å’Œå¢å¼ºæ•°æ®
    x_combined = np.concatenate([train_x, x_augmented], axis=0)
    y_combined = np.concatenate([train_y, y_augmented], axis=0)

    return x_combined, y_combined


def mix_and_expand_data_with_subjects(train_x, train_y, subject_labels, augmentation_function, augment_ratio=0.3):
    """
    å¯¹ EEG æ•°æ®å’Œ subject_labels ä¸€èµ·åšå¢å¼ºå’Œæ‰©å±•ã€‚
    """
    total_samples = len(train_x)
    num_augmented = int(total_samples * augment_ratio)

    # éšæœºé€‰æ‹©éœ€è¦å¢å¼ºçš„æ ·æœ¬ç´¢å¼•
    indices_to_augment = np.random.choice(total_samples, size=num_augmented, replace=False)

    # æå–éœ€è¦å¢å¼ºçš„æ•°æ®
    x_to_augment = train_x[indices_to_augment]
    y_to_augment = train_y[indices_to_augment]
    subj_to_augment = subject_labels[indices_to_augment]

    # åšå¢å¼º
    x_augmented = augmentation_function(x_to_augment)
    y_augmented = np.copy(y_to_augment)
    subj_augmented = np.copy(subj_to_augment)

    # åˆå¹¶æ‰€æœ‰
    x_combined = np.concatenate([train_x, x_augmented], axis=0)
    y_combined = np.concatenate([train_y, y_augmented], axis=0)
    subj_combined = np.concatenate([subject_labels, subj_augmented], axis=0)

    return x_combined, y_combined, subj_combined


def segment_data_and_labels(data, labels, window_size=900, step_size=250):
    """
    å¯¹å¤šé¢‘å¸¦ EEG æ•°æ®è¿›è¡Œåˆ†å‰²ï¼Œå¹¶æ‰©å±•æ ‡ç­¾ä»¥åŒ¹é…åˆ†å‰²åçš„æ•°æ®ã€‚

    å‚æ•°:
    data: è¾“å…¥çš„ EEG æ•°æ®ï¼Œå½¢çŠ¶ä¸º (n_trials, 2, n_channels, n_bands, n_samples)
    labels: è¾“å…¥çš„æ ‡ç­¾ï¼Œå½¢çŠ¶ä¸º (n_trials,)
    window_size: æ¯ä¸ªçª—å£çš„å¤§å°ï¼ˆæ—¶é—´æ­¥é•¿ï¼‰
    step_size: çª—å£ä¹‹é—´çš„æ­¥é•¿

    è¿”å›:
    segmented_data: åˆ†å‰²åçš„ EEG æ•°æ®ï¼Œå½¢çŠ¶ä¸º (n_windows, 2, n_channels, n_bands, window_size)
    expanded_labels: æ‰©å±•åçš„æ ‡ç­¾ï¼Œå½¢çŠ¶ä¸º (n_windows,)
    """
    n_trials, n_channels, n_samples = data.shape[0], data.shape[2], data.shape[3]
    segmented_data = []
    expanded_labels = []

    for trial_idx in range(n_trials):
        trial_data = data[trial_idx]  # å½¢çŠ¶ä¸º (2, n_channels, n_bands, n_samples)
        trial_label = labels[trial_idx]

        # å¯¹æ¯ä¸ª trial çš„æ•°æ®æŒ‰æ—¶é—´æ­¥è¿›è¡Œåˆ†å‰²
        for start in range(0, n_samples - window_size + 1, step_size):
            # å–å½“å‰çª—å£çš„æ•°æ®ï¼Œå½¢çŠ¶ä¸º (2, n_channels, n_bands, window_size)
            window_data = trial_data[:, :, start:start + window_size]
            segmented_data.append(window_data)
            expanded_labels.append(trial_label)  # æ ‡ç­¾æ‰©å±•ä»¥åŒ¹é…åˆ†å‰²åçš„æ•°æ®

    # å°†åˆ—è¡¨è½¬æ¢ä¸º numpy æ•°ç»„
    segmented_data = np.array(segmented_data)
    expanded_labels = np.array(expanded_labels)

    return segmented_data, expanded_labels


def expand_subject_labels(subject_labels, data, window_size=900, step_size=250):
    """
    æ ¹æ® EEG trial åˆ†å‰²æ•°é‡æ‰©å±•å—è¯•è€…æ ‡ç­¾ã€‚

    å‚æ•°:
    subject_labels: åŸå§‹ trial çº§åˆ«çš„ subject æ ‡ç­¾ï¼Œå½¢çŠ¶ä¸º (n_trials,)
    data: EEG æ•°æ®ï¼Œå½¢çŠ¶ä¸º (n_trials, n_bands, n_channels, n_samples)
    window_size: æ»‘åŠ¨çª—å£å¤§å°
    step_size: æ»‘åŠ¨çª—å£æ­¥é•¿

    è¿”å›:
    expanded_subject_labels: æ‰©å±•åçš„ subject æ ‡ç­¾ï¼Œå½¢çŠ¶ä¸º (n_windows,)
    """
    n_trials, _, _, n_samples = data.shape
    expanded_subject_labels = []

    for i in range(n_trials):
        n_windows = (n_samples - window_size) // step_size + 1
        expanded_subject_labels.extend([subject_labels[i]] * n_windows)

    return np.array(expanded_subject_labels)


def apply_mne_filter_split(data, sfreq, l_freq, h_freq, save_path=None, band_name=None):
    """
    ä½¿ç”¨ MNE è¿›è¡Œåˆ†æ­¥æ»¤æ³¢ï¼ˆå…ˆä½é€šåé«˜é€šï¼‰ï¼Œå¾—åˆ°æŒ‡å®šé¢‘å¸¦çš„ EEG ä¿¡å·ã€‚

    å‚æ•°:
    data: ndarray, EEG æ•°æ®ï¼Œå½¢çŠ¶ (batch_size, num_channels, time_steps)
    sfreq: float, é‡‡æ ·ç‡
    l_freq: float, ä½æˆªæ­¢é¢‘ç‡
    h_freq: float, é«˜æˆªæ­¢é¢‘ç‡
    save_path: str, æ»¤æ³¢ç»“æœä¿å­˜è·¯å¾„
    band_name: str, æ»¤æ³¢é¢‘å¸¦åç§°

    è¿”å›:
    filtered_data: ndarray, æ»¤æ³¢åçš„ EEG æ•°æ®
    """

    batch_size, num_channels, time_steps = data.shape
    data_reshaped = data  # ä¸ reshapeï¼Œç›´æ¥æŒ‰ (batch, channels, time)

    # æ»¤æ³¢å‚æ•°è®¾ç½®
    fir_window = 'hamming'
    phase_type = 'zero-double'

    if band_name:
        print(
            f"Filtering band '{band_name}' with two-step filtering: "
            f"1) lowpass at {h_freq} Hz, 2) highpass at {l_freq} Hz"
        )

    # ç¬¬ä¸€æ­¥ï¼šä½é€šæ»¤æ³¢ (â‰¤ h_freq)
    data_lowpassed = mne.filter.filter_data(
        data_reshaped, sfreq=sfreq, l_freq=None, h_freq=h_freq,
        method='fir', fir_design='firwin', phase=phase_type, pad='reflect_limited', fir_window=fir_window,
    )

    # ç¬¬äºŒæ­¥ï¼šé«˜é€šæ»¤æ³¢ (â‰¥ l_freq)
    filtered_data = mne.filter.filter_data(
        data_lowpassed, sfreq=sfreq, l_freq=l_freq, h_freq=None,
        method='fir', fir_design='firwin', phase=phase_type, pad='reflect_limited', fir_window=fir_window,
    )

    # ä¿å­˜ç»“æœ
    if save_path and band_name:
        save_dir = os.path.join(save_path, f"filtered_{band_name}.npy")
        os.makedirs(os.path.dirname(save_dir), exist_ok=True)
        np.save(save_dir, filtered_data)
        print(f"Filtered data for {band_name} saved to {save_dir}.")

    return filtered_data


class BandAttentionFusion(nn.Module):
    def __init__(self, channels=64):
        super().__init__()

        # å…¬å…±ç‰¹å¾æ•´åˆé—¨æ§
        self.shared_gate1 = nn.Sequential(
            nn.Conv1d(channels * 3, channels, kernel_size=1),
            #nn.BatchNorm1d(channels),
            nn.Sigmoid()
        )

        self.shared_gate2 = nn.Sequential(
            nn.Conv1d(channels * 3, channels, kernel_size=1),
            #nn.BatchNorm1d(channels),
            nn.Tanh()
        )

        self.forgot = nn.Sequential(
            nn.Conv1d(channels, channels, kernel_size=1),
            #nn.BatchNorm1d(channels),
            nn.Sigmoid()
        )
        self.out_proj = nn.Sequential(
            nn.Conv1d(channels, channels, kernel_size=1),
            nn.BatchNorm1d(channels),
            nn.ELU(),
            nn.Dropout(0.3)
        )

    def forward(self, mu, beta, gamma):

        # é€šç”¨é—¨æ§ï¼ˆå‹ç¼©ä¸‰é¢‘æ®µå…±æ€§ï¼‰
        concat = torch.cat([mu, beta, gamma], dim=1)           # [B, C*3, T]
        Cell = mu+beta+gamma

        gate1 = self.shared_gate1(concat)
        gate2 = self.shared_gate2(concat)

        cell = self.forgot(Cell)

        # åŠ é—¨æ§æ®‹å·®èåˆ
        x_fused = gate1*gate2+cell
        #out = self.out_proj(x_fused)

        return x_fused


class MSCNNBlock(nn.Module):
    def __init__(self, in_channels, out_channels=64):
        super().__init__()
        self.conv_d1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1, dilation=1)
        self.conv_d2 = nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=2, dilation=2)
        self.conv_d3 = nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=3, dilation=3)

        self.fusion = nn.Sequential(
            nn.Conv1d(out_channels * 3, out_channels, kernel_size=1),
            nn.BatchNorm1d(out_channels),
            nn.ELU()
        )
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x1 = self.conv_d1(x)
        x2 = self.conv_d2(x)
        x3 = self.conv_d3(x)
        x_cat = torch.cat([x1, x2, x3], dim=1)  # å¤šå°ºåº¦æ‹¼æ¥
        out = self.fusion(x_cat)               # [B, out_channels, T]
        out = self.dropout(out)
        return out


def _make_divisible(v, divisor, min_value=None):
    """
    This function is taken from the original tf repo.
    It ensures that all layers have a channel number that is divisible by 8
    It can be seen here:
    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py
    """
    if min_value is None:
        min_value = divisor
    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)
    # Make sure that round down does not go down by more than 10%.
    if new_v < 0.9 * v:
        new_v += divisor
    return new_v


def hard_sigmoid(x, inplace: bool = False):
    if inplace:
        return x.add_(3.).clamp_(0., 6.).div_(6.)
    else:
        return F.relu6(x + 3.) / 6.


class SqueezeExcite(nn.Module):
    def __init__(self, in_chs, se_ratio=0.25, reduced_base_chs=None,
                 act_layer=nn.ReLU, gate_fn=hard_sigmoid, divisor=4, **_):
        super(SqueezeExcite, self).__init__()
        self.gate_fn = gate_fn
        reduced_chs = _make_divisible((reduced_base_chs or in_chs) * se_ratio, divisor)
        self.avg_pool = nn.AdaptiveAvgPool1d(1)
        self.conv_reduce = nn.Conv1d(in_chs, reduced_chs, 1, bias=True)
        self.act1 = act_layer(inplace=True)
        self.conv_expand = nn.Conv1d(reduced_chs, in_chs, 1, bias=True)

    def forward(self, x):
        x_se = self.avg_pool(x)
        x_se = self.conv_reduce(x_se)
        x_se = self.act1(x_se)
        x_se = self.conv_expand(x_se)
        x = x * self.gate_fn(x_se)
        return x


class DenseNet1D(nn.Module):
    def __init__(self, in_channels=48, mid_channels=64, hidden_dims=[64, 64],
                 dropout_rate=0.1, num_classes=11):
        super().__init__()

        self.residual = nn.Conv1d(in_channels, mid_channels, kernel_size=1)

        self.conv_mu = MSCNNBlock(in_channels)
        self.conv_beta = MSCNNBlock(in_channels)
        self.conv_gamma = MSCNNBlock(in_channels)

        self.mu_SE = SqueezeExcite(48)
        self.beta_SE = SqueezeExcite(48)
        self.gamma_SE = SqueezeExcite(48)

        self.conv_delta = nn.Sequential(nn.Conv1d(11, 64, kernel_size=15, padding=7, dilation=1),
                                        nn.BatchNorm1d(64),
                                        nn.ELU(),
                                        # nn.MaxPool1d(4, 4),
                                        nn.Dropout(0.3))

        self.band_fusion = BandAttentionFusion()
        # å¯å­¦ä¹ æƒé‡ç³»æ•°
        self.alpha = nn.Parameter(torch.tensor(0.5))
        self.beta = nn.Parameter(torch.tensor(0.5))  # å¯å­¦ä¹ èåˆæƒé‡

        self.max_pooling = nn.MaxPool1d(2, 2)
        self.avg_pooling = nn.AvgPool1d(2, 2)

        self.pool = nn.AdaptiveAvgPool1d(1)

        self.lstm1 = nn.LSTM(input_size=64, hidden_size=64, bidirectional=True)
        self.lstm2 = nn.LSTM(input_size=128, hidden_size=64, bidirectional=True)
        self.drop_out1 = nn.Dropout(0.3)
        self.drop_out2 = nn.Dropout(0.3)
        self.layer_norm1 = nn.LayerNorm(64)
        self.layer_norm2 = nn.LayerNorm(128)
        self.fc = nn.Linear(128, 64)

        self.res_proj1 = nn.Linear(64, 128)  # ç”¨äº LSTM1 æ®‹å·®
        self.res_proj2 = nn.Identity()  # å¦‚æœä¸¤æ¬¡è¾“å‡ºç»´åº¦ä¸€æ ·å¯ä»¥ä¸æ˜ å°„

    def forward(self, delta, mu, beta, gamma):
        # x: [B, 6, T]
        delta = self.conv_delta(delta)
        mu = self.conv_mu(self.mu_SE(mu))
        beta = self.conv_beta(self.beta_SE(beta))
        gamma = self.conv_gamma(self.gamma_SE(gamma))
        x = self.band_fusion(mu, beta, gamma) + self.alpha*delta

        #x = self.pooling(x)
        #max_out = self.max_pooling(x)  # (B, C, T')
        #avg_out = self.avg_pooling(x)
        #x = torch.cat([max_out, avg_out], dim=1)  # (B, 2C, T')
        x = self.max_pooling(x)
        x = x.permute(0, 2, 1)

        res1 = x
        x = self.layer_norm1(x)
        x, _ = self.lstm1(x)
        x = self.drop_out1(x)
        if res1.shape[-1] != x.shape[-1]:
            res1 = self.res_proj1(res1)
        x = x + res1  # æ®‹å·®è¿æ¥

        res2 = x
        x = self.layer_norm2(x)
        x, _ = self.lstm2(x)
        x = self.drop_out2(x)
        if res2.shape[-1] != x.shape[-1]:
            res2 = self.res_proj2(res2)
        x = x + res2  # ç¬¬äºŒæ¬¡æ®‹å·®

        # === Transformer å‰å¯ä»¥å† LayerNormï¼ˆå¯é€‰ï¼‰===
        # x = self.transformer(x)
        x1 = torch.mean(x, dim=1)  # å…¨å±€å¹³å‡æ± åŒ–ï¼š [B, hidden_dim]
        x2 = x[:, -1]
        x = x1
        x = self.fc(x)
        return x


def select_band_channels(x, band, return_indices=False):
    """
    ä» EEG è¾“å…¥å¼ é‡ä¸­é€‰æ‹©æŒ‡å®šé¢‘æ®µå¯¹åº”çš„è„‘åŒºé€šé“ã€‚

    å‚æ•°ï¼š
    x: torch.Tensor, å½¢çŠ¶ä¸º (B, bands, C, T)
    band: str, 'mu', 'beta', 'gamma', æˆ– 'delta'
    return_indices: æ˜¯å¦è¿”å›é€šé“ç´¢å¼•ï¼ˆè°ƒè¯•ç”¨ï¼‰

    è¿”å›ï¼š
    x_band_selected: é€‰ä¸­é€šé“çš„æ•°æ® (B, C_selected, T)
    """
    # æ‰€æœ‰ç”µæé€šé“é¡ºåºï¼ˆä¸åŸå§‹æ•°æ®é¡ºåºä¿æŒä¸€è‡´ï¼‰
    channel_columns = [
        # Group 1 â€“ Broca's & Wernicke's Area
        'FT8', 'T7', 'P3', 'C3', 'C5', 'C4', 'FC6', 'F5', 'F3', 'FC3', 'FC5',
        # Group 2 â€“ Motor Cortex
        'C3', 'C5', 'C1', 'CZ', 'C2', 'C4', 'FC1', 'FCZ', 'FC2', 'FC6', 'FC4',
        # Group 3 â€“ Frontal Lobe
        'F1', 'FZ', 'F2', 'F4', 'F6', 'FCZ', 'FC2', 'FPZ', 'FP2', 'AF3', 'AF4',
        # Group 4 â€“ Parietal & Occipital Lobes
        'P1', 'P2', 'P4', 'PZ', 'POZ', 'PO4', 'PO6', 'CP3', 'CP5', 'CP1', 'CPZ',
        # Group 5 â€“ Insular Approx. Area
        'F8', 'T8', 'TP8', 'P8'
    ]

    # é€šé“ååˆ°ç´¢å¼•
    channel_to_index = {}
    for i, ch in enumerate(channel_columns):
        if ch not in channel_to_index:
            channel_to_index[ch] = i

    band_to_channels = {
        'delta': ['P1', 'P2', 'PZ', 'POZ', 'CPZ', 'CP3', 'CP5', 'CP1', 'CZ', 'PO4', 'T7'],  # â¤ è¯­è¨€æ³¨æ„+æ•´åˆåŒº 11channels
        'mu': ['C3', 'C5', 'C1', 'CZ', 'C2', 'C4', 'FC1', 'FCZ', 'FC2', 'FC6', 'FZ', 'F4'], #12
        'beta': ['F3', 'F5', 'FC3', 'FC5', 'C3', 'C5', 'P3', 'C4', 'T7',
                 'FC6', 'F8', 'T8', 'FT8'],#13
        'gamma': ['F1', 'F2', 'F6', 'FCZ', 'FC2', 'C3', 'C4', 'CZ', 'CP3',
                  'P1', 'P2', 'P4', 'PZ', 'POZ', 'PO4', 'PO6', 'TP8', 'P8', 'FC3', 'FC4'],#20
    }

    band_map = {'delta': 0, 'mu': 1, 'beta': 2, 'gamma': 3}
    assert band in band_map, f"æ— æ•ˆé¢‘æ®µï¼š{band}"
    band_idx = band_map[band]

    indices = [channel_to_index[ch] for ch in band_to_channels[band] if ch in channel_to_index]
    x_band = x[:, band_idx][:, indices, :]  # [B, C_selected, T]

    return (x_band, indices) if return_indices else x_band


class EEGRegionModel(nn.Module):
    def __init__(self, hidden_size, num_layers, num_classes, embed_size, num_channels=64):
        super(EEGRegionModel, self).__init__()

        self.num_bands = 6

        self.convLSTM1 = DenseNet1D()

        self.pos_embedding = nn.Parameter(torch.randn(1, 3844, 128))

        self.flatten = nn.Flatten()

        self.alpha = nn.Parameter(torch.tensor(0.5))  # å¯å­¦ä¹ å‚æ•°

    def forward(self, x):
        #mu_input = select_band_channels(x, 'mu')  # x: [B, 3, C, T]
        #beta_input = select_band_channels(x, 'beta')
        #gamma_input = select_band_channels(x, 'gamma')
        delta_input = select_band_channels(x, 'delta')
        #delta_input = x[:, 0]
        mu_input = x[:, 1]
        beta_input = x[:, 2]
        gamma_input = x[:, 3]

        output = self.convLSTM1(delta_input, mu_input, beta_input, gamma_input)

        return output


# å®ä¾‹åŒ–æ–°çš„ EEGRegionModel
embed_dim = 128  # 5 ä¸ªè„‘åŒºçš„è¾“å‡ºæ‹¼æ¥
num_heads = 4  # å¤šå¤´æ³¨æ„åŠ›çš„å¤´æ•°
hidden_size = 128  # LSTMçš„éšå±‚å¤§å°
num_layers = 1  # LSTMå±‚æ•°
num_classes = 11  # åˆ†ç±»ç±»åˆ«æ•°

# åˆ›å»ºæ¨¡å‹å®ä¾‹
model = EEGRegionModel(hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes,
                       embed_size=embed_dim).cuda()


# æ‰“å°æ¨¡å‹ç»“æ„
# print(model)


class EarlyStopping:
    def __init__(self, patience=10, delta=1e-4):
        """
        :param patience: éªŒè¯å‡†ç¡®ç‡å¤šå°‘ä¸ª epoch æ²¡æå‡å°±åœæ­¢
        :param delta: è®¤ä¸ºâ€œæœ‰æå‡â€çš„æœ€å°å¢é‡
        """
        self.patience = patience
        self.delta = delta
        self.counter = 0
        self.best_score = None
        self.early_stop = False

    def __call__(self, val_acc):
        if self.best_score is None:
            self.best_score = val_acc
        elif val_acc < self.best_score + self.delta:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = val_acc
            self.counter = 0


def downsample_safely(data, original_fs, target_fs):
    """
    å¯¹ shape = (B, bands, C, T) çš„å¤šé¢‘æ®µ EEG æ•°æ®è¿›è¡ŒæŠ—æ··å é™é‡‡æ ·ã€‚
    è¿”å› shape = (B, bands, C, Tâ†“)
    """
    from mne.filter import resample

    assert data.ndim == 4, "è¾“å…¥å¿…é¡»æ˜¯ (B, bands, C, T)"
    B, bands, C, T = data.shape
    ratio = target_fs / original_fs

    downsampled = []

    for i in range(bands):
        band_data = data[:, i]  # shape: (B, C, T)
        band_down = resample(band_data, down=1 / ratio, npad='auto')  # shape: (B, C, Tâ†“)
        downsampled.append(band_down)

    # å †å å› (B, bands, C, Tâ†“)
    return np.stack(downsampled, axis=1)


def draw_tsne_embeddings(model, X, y, subject_labels, save_path=None, title="t-SNE of EEG Embeddings"):
    """
    å°†æ¨¡å‹è¾“å‡ºçš„ EEG embedding æ˜ å°„åˆ°2Dç©ºé—´å¹¶æŒ‰å—è¯•è€…å¯è§†åŒ–
    å‚æ•°ï¼š
        model: è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ˆéœ€åŒ…å«æå– embedding çš„å‰å‘éƒ¨åˆ†ï¼‰
        X: [N, C, T] EEGæ•°æ® tensor
        y: [N] ç±»åˆ«æ ‡ç­¾ tensor
        subject_labels: [N] æ¯ä¸ªæ ·æœ¬å¯¹åº”çš„ subject_idï¼ˆæ•´æ•°æˆ–å­—ç¬¦ä¸²ï¼‰
        save_path: å¦‚æœæä¾›ï¼Œä¼šä¿å­˜å›¾ç‰‡ï¼›å¦åˆ™ç›´æ¥ plt.show()
    """
    model.eval()
    with torch.no_grad():
        embeddings = model(X).cpu().numpy()

    subject_labels = subject_labels.cpu().numpy()
    tsne = TSNE(n_components=2, perplexity=30, init='pca', random_state=0)
    X_tsne = tsne.fit_transform(embeddings)

    plt.figure(figsize=(10, 8))
    palette = sns.color_palette("hsv", len(set(subject_labels)))
    sns.scatterplot(x=X_tsne[:, 0], y=X_tsne[:, 1], hue=subject_labels, palette=palette, s=40, alpha=0.8)

    plt.title(title)
    plt.xlabel("t-SNE 1")
    plt.ylabel("t-SNE 2")
    plt.legend(title="Subject ID", bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.tight_layout()

    if save_path:
        plt.savefig(save_path, dpi=300)
        print(f"t-SNE å›¾å·²ä¿å­˜åˆ°: {save_path}")
    else:
        plt.show()


def compute_phase_envelope(epoch_band, batch_size=64, fs=500, cutoff=5):
    """
    è®¡ç®—æ¯ä¸ªé¢‘æ®µçš„ç›¸ä½å’ŒåŒ…ç»œï¼Œå¹¶å¯¹åŒ…ç»œè¿›è¡Œä½é€šæ»¤æ³¢å’Œæ ‡å‡†åŒ–ã€‚

    å‚æ•°:
        epoch_band: np.array shape (B, bands, C, T)
        batch_size: æ‰¹å¤„ç†å¤§å°
        fs: é‡‡æ ·ç‡ (é»˜è®¤ 500Hz)
        cutoff: åŒ…ç»œä½é€šæ»¤æ³¢æˆªæ­¢é¢‘ç‡ (é»˜è®¤ 5Hz)

    è¿”å›:
        phase: ç›¸ä½ (B, bands, C, T)
        envelope_z: æ ‡å‡†åŒ–åçš„åŒ…ç»œ (B, bands, C, T)
    """
    B, bands, C, T = epoch_band.shape

    # åˆå§‹åŒ–ç›¸ä½å’ŒåŒ…ç»œçŸ©é˜µ
    phase = np.zeros((B, bands, C, T))
    envelope = np.zeros((B, bands, C, T))

    # å¯¹æ¯ä¸ªé¢‘å¸¦å¤„ç†
    for band_idx in range(bands):
        for i in range(0, B, batch_size):  # åˆ†æ‰¹æ¬¡å¤„ç†
            batch_data = epoch_band[i:i + batch_size, band_idx, :, :]  # å½“å‰æ‰¹æ¬¡çš„æ•°æ® (batch, C, T)

            # Hilbertå˜æ¢æå–ç›¸ä½å’ŒåŒ…ç»œ
            analytic_signal = hilbert(batch_data, axis=-1)  # (batch, C, T)
            phase[i:i + batch_size, band_idx] = np.angle(analytic_signal)  # ç›¸ä½
            envelope_batch = np.abs(analytic_signal)  # åŸå§‹åŒ…ç»œ

            # å­˜å‚¨æ»¤æ³¢åçš„åŒ…ç»œ
            envelope[i:i + batch_size, band_idx] = envelope_batch

    envelope_z = envelope  # æ ‡å‡†åŒ–åçš„åŒ…ç»œ

    return envelope_z


# === 1. åˆ›å»º Prototypical Network çš„ Episode ===
def create_episode(X, y, n_way=11, k_shot=5, q_query=10):
    device = X.device
    classes = torch.unique(y).cpu()
    assert len(classes) >= n_way, f"æ•°æ®ä¸­ç±»åˆ«æ•°ä¸è¶³ {n_way}"

    selected_classes = classes[torch.randperm(len(classes))[:n_way]]
    support_x, support_y, query_x, query_y = [], [], [], []

    for i, cls in enumerate(selected_classes):
        cls_idx = (y == cls).nonzero(as_tuple=True)[0]
        if len(cls_idx) < k_shot + q_query:
            raise ValueError(f"ç±»åˆ« {cls.item()} çš„æ ·æœ¬æ•°ä¸è¶³ï¼ˆéœ€è¦ {k_shot + q_query}ï¼‰")
        selected = cls_idx[torch.randperm(len(cls_idx))[:k_shot + q_query]]
        support_x.append(X[selected[:k_shot]])
        query_x.append(X[selected[k_shot:]])
        support_y.append(torch.full((k_shot,), i, device=device))
        query_y.append(torch.full((q_query,), i, device=device))

    x = torch.cat(support_x + query_x, dim=0)
    y_ep = torch.cat(support_y + query_y, dim=0)

    return x, y_ep


def create_episode_diverse_support_fixed_query_subject(X, y, subject_labels, n_way=11, k_shot=5, q_query=10):
    """
    - Support: æ¥è‡ªä¸åŒçš„å—è¯•è€…ï¼Œæ¯ä¸ªæ ·æœ¬ä¸€ä¸ªå—è¯•
    - Query: ä»ä¸€ä¸ªæœªè¢« support ä½¿ç”¨çš„å—è¯•è€…ä¸­é€‰å–
    """
    import torch
    import random

    assert X.shape[0] == y.shape[0] == subject_labels.shape[0], "ğŸš¨ è¾“å…¥æ•°é‡ä¸åŒ¹é…ï¼"
    assert subject_labels.device == y.device and y.device == X.device, "ğŸš¨ æ‰€æœ‰è¾“å…¥åº”åœ¨åŒä¸€ deviceï¼"

    device = X.device
    classes = torch.unique(y)
    assert len(classes) >= n_way, f"ç±»åˆ«æ•°ä¸è¶³ {n_way}"

    selected_classes = classes[torch.randperm(len(classes))[:n_way]]
    support_x, support_y, query_x, query_y = [], [], [], []

    for i, cls in enumerate(selected_classes):
        cls_idx = (y == cls).nonzero(as_tuple=True)[0]
        cls_subjs = subject_labels[cls_idx]
        unique_subs = torch.unique(cls_subjs)

        if len(cls_idx) < k_shot + q_query or len(unique_subs) < 2:
            continue

        # âœ… å°½å¯èƒ½ä»ä¸åŒå—è¯•è€…ä¸­é€‰æ‹© supportï¼ˆæ¯äººä¸€ä¸ªæ ·æœ¬ï¼‰
        support_idx = []
        support_subs_selected = []
        candidate_subs = unique_subs.tolist()
        random.shuffle(candidate_subs)

        for subj in candidate_subs:
            subj_idx = cls_idx[(cls_subjs == subj).nonzero(as_tuple=True)[0]]
            if len(subj_idx) == 0:
                continue
            pick = subj_idx[torch.randint(0, len(subj_idx), (1,)).item()]
            support_idx.append(pick.item())
            support_subs_selected.append(subj)
            if len(support_idx) >= k_shot:
                break

        if len(support_idx) < k_shot:
            continue

        # âœ… Query ä»æœªç”¨è¿‡çš„å—è¯•ä¸­é€‰ä¸€ä¸ªäºº
        remaining_subs = [s for s in unique_subs.tolist() if s not in support_subs_selected]
        if len(remaining_subs) == 0:
            continue

        query_subj = random.choice(remaining_subs)
        query_pool = cls_idx[(cls_subjs == query_subj).nonzero(as_tuple=True)[0]]
        if len(query_pool) < q_query:
            continue

        q_sel = query_pool[torch.randperm(len(query_pool))[:q_query]]
        s_sel = torch.tensor(support_idx, device=device)

        support_x.append(X[s_sel])
        query_x.append(X[q_sel])
        support_y.append(torch.full((k_shot,), i, dtype=torch.long, device=device))
        query_y.append(torch.full((q_query,), i, dtype=torch.long, device=device))

    if not support_x or not query_x:
        raise ValueError("âŒ æ— æ³•æ„é€ æœ‰æ•ˆ episodeï¼Œè¯·æ£€æŸ¥æ•°æ®æ˜¯å¦è¶³å¤Ÿ")

    x_ep = torch.cat(support_x + query_x, dim=0)
    y_ep = torch.cat(support_y + query_y, dim=0)
    return x_ep, y_ep


def create_episode_diverse_support_balanced_query(X, y, subject_labels, n_way=11, k_shot=5, q_query=10):
    """
    æ¯ä¸ª episode æ„é€ ï¼š
    - support: æ¯ç±»ä»ä¸åŒçš„ subject å– k_shot ä¸ªæ ·æœ¬
    - query: ä»å‰©ä¸‹çš„ subject ä¸­ï¼Œå°½é‡å¹³å‡åœ°åˆ†é… q_query ä¸ªæ ·æœ¬
    """

    import torch
    import random

    assert X.shape[0] == y.shape[0] == subject_labels.shape[0], "âŒ è¾“å…¥ç»´åº¦ä¸ä¸€è‡´"
    device = X.device
    support_x, support_y, query_x, query_y = [], [], [], []

    classes = torch.unique(y)
    assert len(classes) >= n_way, "âŒ ç±»åˆ«æ•°ä¸è¶³ n_way"

    selected_classes = classes[torch.randperm(len(classes))[:n_way]]

    for i, cls in enumerate(selected_classes):
        cls_idx = (y == cls).nonzero(as_tuple=True)[0]
        cls_subj = subject_labels[cls_idx]
        unique_subj = torch.unique(cls_subj)

        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„å—è¯•æ”¯æŒ support + query
        if len(unique_subj) < 2:
            continue

        # === Step 1: æ„å»º supportï¼ˆæ¥è‡ªä¸åŒå—è¯•ï¼‰
        support_idx = []
        support_subjs_used = []
        candidate_subs = unique_subj.tolist()
        random.shuffle(candidate_subs)

        for subj in candidate_subs:
            subj_idx = cls_idx[(cls_subj == subj).nonzero(as_tuple=True)[0]]
            if len(subj_idx) == 0:
                continue
            pick = subj_idx[torch.randint(0, len(subj_idx), (1,)).item()]
            support_idx.append(pick.item())
            support_subjs_used.append(subj)
            if len(support_idx) >= k_shot:
                break

        if len(support_idx) < k_shot:
            continue

        # === Step 2: æ„å»º queryï¼ˆä»å‰©ä¸‹çš„å—è¯•ä¸­å¹³å‡æŠ½å–ï¼‰
        remaining_subs = [s for s in unique_subj.tolist() if s not in support_subjs_used]
        if len(remaining_subs) == 0:
            continue

        query_idx = []
        # å°½å¯èƒ½å¹³å‡åœ°ä»æ¯ä¸ªå‰©ä½™å—è¯•ä¸­æŠ½æ ·
        while len(query_idx) < q_query and remaining_subs:
            for subj in remaining_subs:
                if len(query_idx) >= q_query:
                    break
                subj_pool = cls_idx[(cls_subj == subj).nonzero(as_tuple=True)[0]]
                if len(subj_pool) == 0:
                    continue
                pick = subj_pool[torch.randint(0, len(subj_pool), (1,)).item()]
                query_idx.append(pick.item())

        if len(query_idx) < q_query:
            continue

        # === æ„å»º support/query æ ·æœ¬
        s_sel = torch.tensor(support_idx, device=device)
        q_sel = torch.tensor(query_idx, device=device)

        support_x.append(X[s_sel])
        support_y.append(torch.full((k_shot,), i, dtype=torch.long, device=device))

        query_x.append(X[q_sel])
        query_y.append(torch.full((q_query,), i, dtype=torch.long, device=device))

    if not support_x or not query_x:
        raise ValueError("âŒ æ— æ³•æ„é€ æœ‰æ•ˆ episodeï¼Œè¯·æ£€æŸ¥æ•°æ®æˆ–å‚æ•°")

    x_ep = torch.cat(support_x + query_x, dim=0)
    y_ep = torch.cat(support_y + query_y, dim=0)
    return x_ep, y_ep


# === 2. åŸå‹ç½‘ç»œæŸå¤±å‡½æ•° ===
def prototypical_loss(embeddings, targets, n_support):
    target_set = torch.unique(targets)
    n_classes = len(target_set)

    support_idx, query_idx = [], []
    for cls in target_set:
        cls_idx = (targets == cls).nonzero(as_tuple=True)[0]
        support_idx.append(cls_idx[:n_support])
        query_idx.append(cls_idx[n_support:])

    support_idx = torch.cat(support_idx)
    query_idx = torch.cat(query_idx)

    support_embeddings = embeddings[support_idx]
    query_embeddings = embeddings[query_idx]
    support_targets = targets[support_idx]
    query_targets = targets[query_idx]

    prototypes = []
    for cls in range(n_classes):
        cls_support = support_embeddings[support_targets == cls]
        prototypes.append(cls_support.mean(dim=0))
    prototypes = torch.stack(prototypes)

    dists = torch.cdist(query_embeddings, prototypes)
    log_p_y = F.log_softmax(-dists, dim=1)

    loss = F.nll_loss(log_p_y, query_targets)
    preds = torch.argmax(log_p_y, dim=1)
    acc = (preds == query_targets).float().mean()

    return loss, acc, preds, query_targets


def dual_metric_prototypical_loss(embeddings, targets, n_support, alpha=0.5):
    """
    :param embeddings: [N, D] è¾“å…¥ç‰¹å¾
    :param targets: [N] å¯¹åº”æ ‡ç­¾ï¼Œå·²ç»æ˜¯å±€éƒ¨ 0ï½n_classes-1 çš„ç´¢å¼•ï¼
    :param n_support: æ¯ç±» support æ ·æœ¬æ•°
    :param alpha: æ··åˆç³»æ•°ï¼Œ0.0 = çº¯æ¬§å‡ é‡Œå¾—ï¼Œ1.0 = çº¯ä½™å¼¦è·ç¦»
    :return: loss, acc, preds, query_targets
    """

    # è·å–å½“å‰ episode ä¸­çš„ç±»åˆ«
    target_set = torch.unique(targets)
    n_classes = len(target_set)

    support_idx, query_idx = [], []
    for cls in target_set:
        cls_idx = (targets == cls).nonzero(as_tuple=True)[0]
        support_idx.append(cls_idx[:n_support])
        query_idx.append(cls_idx[n_support:])

    support_idx = torch.cat(support_idx)
    query_idx = torch.cat(query_idx)

    support_embeddings = embeddings[support_idx]
    query_embeddings = embeddings[query_idx]
    support_targets = targets[support_idx]
    query_targets = targets[query_idx]

    # === 1. åŸå‹æ„é€  ===
    prototypes = []
    for cls in range(n_classes):
        cls_support = support_embeddings[support_targets == cls]
        prototypes.append(cls_support.mean(dim=0))
    prototypes = torch.stack(prototypes)  # [n_classes, D]

    # === 2. æ¬§å‡ é‡Œå¾—è·ç¦» ===
    euclidean_dists = torch.cdist(query_embeddings, prototypes, p=2)  # [N_query, N_classes]

    # === 3. ä½™å¼¦ç›¸ä¼¼åº¦ ===
    # å…ˆå½’ä¸€åŒ–ï¼ˆå•ä½å‘é‡ï¼‰
    query_norm = F.normalize(query_embeddings, dim=1)
    proto_norm = F.normalize(prototypes, dim=1)
    cosine_sim = torch.matmul(query_norm, proto_norm.T)  # [N_query, N_classes]
    cosine_dists = 1.0 - cosine_sim  # è·ç¦» = 1 - ç›¸ä¼¼åº¦

    # === 4. åŠ æƒèåˆ ===
    combined_dist = alpha * cosine_dists + (1 - alpha) * euclidean_dists

    # === 5. è®¡ç®—æŸå¤± ===
    log_p_y = F.log_softmax(-combined_dist, dim=1)
    loss = F.nll_loss(log_p_y, query_targets)
    preds = torch.argmax(log_p_y, dim=1)
    acc = (preds == query_targets).float().mean()

    return loss, acc, preds, query_targets


# === 3. éªŒè¯ / æµ‹è¯•å‡½æ•° ===
def evaluate_protonet(model, data_x, data_y, save_dir=None, n_way=11, k_shot=5, q_query=10, n_episodes=1):
    device = data_x.device
    model.eval()
    all_preds, all_targets = [], []

    with torch.no_grad():
        for _ in range(n_episodes):
            x_ep, y_ep = create_episode(data_x, data_y, n_way, k_shot, q_query)
            emb = model(x_ep)
            _, _, preds, true = prototypical_loss(emb, y_ep, n_support=k_shot)
            all_preds.append(preds)
            all_targets.append(true)

    all_preds = torch.cat(all_preds).cpu().numpy()
    all_targets = torch.cat(all_targets).cpu().numpy()

    acc = np.mean(all_preds == all_targets)
    cm = confusion_matrix(all_targets, all_preds)
    kappa = cohen_kappa_score(all_targets, all_preds)
    recall = recall_score(all_targets, all_preds, average='macro')
    precision = precision_score(all_targets, all_preds, average='macro')
    f1 = f1_score(all_targets, all_preds, average='macro')
    balanced_acc = balanced_accuracy_score(all_targets, all_preds)

    if save_dir:
        os.makedirs(save_dir, exist_ok=True)
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.0f', cmap='RdPu', linewidths=0.3, linecolor='gray', square=True,
                    cbar_kws={'label': 'Count'})
        plt.title('Confusion Matrix', fontsize=16)
        plt.xlabel('Predicted Label', fontsize=12)
        plt.ylabel('True Label', fontsize=12)
        plt.xticks(fontsize=10)
        plt.yticks(fontsize=10)
        plt.tight_layout()
        plt.savefig(os.path.join(save_dir, 'conf_matrix.png'))
        plt.close()

    return {
        'accuracy': acc,
        'balanced_accuracy': balanced_acc,
        'kappa': kappa,
        'recall': recall,
        'precision': precision,
        'f1': f1,
        'confusion_matrix': cm
    }


def save_accuracy_plot(val_accs, val_checkpoints, save_dir, fold):
    import matplotlib.pyplot as plt
    import os

    plt.figure(figsize=(8, 5))
    plt.plot(val_checkpoints, val_accs, label='Validation Accuracy', color='orange', marker='o')
    plt.xlabel("Episode")
    plt.ylabel("Validation Accuracy")
    plt.title(f"Validation Accuracy Curve - Fold {fold}")
    plt.grid(True)
    plt.legend()
    plt.tight_layout()

    os.makedirs(save_dir, exist_ok=True)
    save_path = os.path.join(save_dir, f"val_accuracy_curve_fold{fold}.png")
    plt.savefig(save_path)
    plt.close()


# å®éªŒç±»ï¼Œå¤„ç†æ•°æ®åŠ è½½ã€è®­ç»ƒå’Œè¯„ä¼°
class ExP():
    def __init__(self, train_data, train_y, test_data, test_y, test_id, path_to_data, train_subject_labels):
        super(ExP, self).__init__()
        self.batch_size = 64
        self.n_epochs = 40
        self.c_dim = 4
        self.lr = 0.0006
        self.b1 = 0.5
        self.b2 = 0.999
        self.train_data = train_data
        self.train_y = train_y
        self.test_data = test_data
        self.test_y = test_y
        self.test_id = test_id
        self.path_to_data = path_to_data  # æ¯ä¸ªå—è¯•è€…çš„æ•°æ®è·¯å¾„
        self.train_subject_labels = train_subject_labels
        self.dimension = (190, 50)
        self.start_epoch = 0

        self.Tensor = torch.cuda.FloatTensor
        self.LongTensor = torch.cuda.LongTensor

        # å®šä¹‰æ¨¡å‹è¶…å‚æ•°
        embed_dim = 128  # 5 ä¸ªè„‘åŒºçš„è¾“å‡ºæ‹¼æ¥
        num_heads = 4  # å¤šå¤´æ³¨æ„åŠ›çš„å¤´æ•°
        hidden_size = 128  # LSTMçš„éšå±‚å¤§å°
        num_layers = 1  # LSTMå±‚æ•°
        num_classes = 11  # åˆ†ç±»ç±»åˆ«æ•°

        # å®šä¹‰æ¨¡å‹å¹¶ä¼ å…¥ embed_dim å’Œ num_heads
        self.model = EEGRegionModel(hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes,
                                    embed_size=embed_dim).cuda()
        self.model = nn.DataParallel(self.model, device_ids=[i for i in range(len(gpus))])
        self.model = self.model.cuda()

    def get_source_data(self):
        # è¯»å–åŸå§‹ã€æ»¤æ³¢å’ŒICAå¤„ç†åçš„æ•°æ®
        # df_raw = load_data(self.path_to_data + self.subject + '/GAM', 'df_epochs_ica_ne.pkl')

        train_x, train_y = self.train_data, self.train_y
        test_x, test_y = self.test_data, self.test_y
        test_id = self.test_id
        train_subject_labels = self.train_subject_labels

        print("X_train.shape", train_x.shape)
        print("train_y.shape", train_y.shape)
        print("test_x.shape", test_x.shape)
        print("test_y.shape", test_y.shape)
        print("test_id", test_id)

        # å®šä¹‰é¢‘å¸¦
        frequency_bands = {
            "delta": (0.5, 4),
            # "theta": (4, 8),
            "mu": (8, 12),
            # "alpha": (8, 13),
            "beta": (13, 30),
            "gamma": (30, 70),
            # "high gamma": (60, 104),
        }

        save_path = os.path.join(self.path_to_data, 'GAM')

        # è·å–åŸå§‹é‡‡æ ·ç‡ï¼ˆå‡è®¾åŸå§‹æ•°æ®é‡‡æ ·ç‡ä¸º1000Hzï¼‰
        original_fs = 1000

        baseline_len = 2000
        train_processed = train_x[:, :, baseline_len:]
        test_processed = test_x[:, :, baseline_len:]

        train_bands = []  # åˆå§‹åŒ–é¢‘å¸¦æ•°æ®åˆ—è¡¨
        test_bands = []

        for band_name, (lowcut, highcut) in frequency_bands.items():
            # æ»¤æ³¢è®­ç»ƒæ•°æ®
            filtered_data_train = apply_mne_filter_split(
                data=train_processed, sfreq=original_fs, l_freq=lowcut, h_freq=highcut, band_name=band_name
            )
            filtered_data_test = apply_mne_filter_split(
                data=test_processed, sfreq=original_fs, l_freq=lowcut, h_freq=highcut, band_name=band_name
            )

            # ä¸ºæ¯ä¸ªé¢‘å¸¦çš„æ•°æ®æ·»åŠ æ–°ç»´åº¦ï¼ˆæ­¤å¤„å‡è®¾æ˜¯ä¸ºäº†é¢‘å¸¦çš„æ‹¼æ¥ï¼‰
            train_bands.append(np.expand_dims(filtered_data_train, axis=1))  # æ·»åŠ åˆ° bands åˆ—è¡¨
            test_bands.append(np.expand_dims(filtered_data_test, axis=1))  # æ·»åŠ åˆ° bands åˆ—è¡¨

        # å°†æ‰€æœ‰é¢‘å¸¦æ•°æ®æ‹¼æ¥åœ¨ä¸€èµ·ï¼ˆåœ¨ç¬¬äºŒç»´è¿›è¡Œæ‹¼æ¥ï¼Œå³é¢‘å¸¦ç»´åº¦ï¼‰
        train_filtered = np.concatenate(train_bands, axis=1)
        train_x = train_filtered

        test_filtered = np.concatenate(test_bands, axis=1)
        test_x = test_filtered

        # åˆå¹¶è®­ç»ƒé›†æ•°æ®ï¼šä½é¢‘ç›¸ä½å’Œé«˜é¢‘åŒ…ç»œ
        train_data = train_x
        test_data = test_x

        print(f"Train data shape after stacking: {train_data.shape}")
        print(f"Test data shape after stacking: {test_data.shape}")

        train_envelope = compute_phase_envelope(train_x)
        test_envelope = compute_phase_envelope(test_x)

        train_x = downsample_safely(train_envelope, 1000, 256)
        test_x = downsample_safely(test_envelope, 1000, 256)

        # åˆ†å‰²è®­ç»ƒå’ŒéªŒè¯æ•°æ®
        segmented_train_x, expanded_train_y = segment_data_and_labels(train_x, train_y, window_size=600,
                                                                      step_size=400)
        segmented_test_x, expanded_test_y = segment_data_and_labels(test_x, test_y, window_size=600,
                                                                    step_size=400)
        # åŒæ­¥æ‰©å±• subject labels
        expanded_train_subject_labels = expand_subject_labels(train_subject_labels, train_x, window_size=600,
                                                              step_size=400)

        # å°†æ‰©å±•åçš„æ ‡ç­¾èµ‹å€¼å› train_y å’Œ val_y
        train_x = segmented_train_x
        test_x = segmented_test_x
        train_y = expanded_train_y
        test_y = expanded_test_y

        train_subject_labels = expanded_train_subject_labels
        print(f"Train X: {train_x.shape}, Train y: {train_y.shape}, Subject Labels: {train_subject_labels.shape}")

        # æ•°æ®å¢å¼º
        #train_x, train_y = mix_and_expand_data(train_x, train_y, augment_data_eeg_bandwise, augment_ratio=0.6)
        #train_x, train_y, train_subject_labels = mix_and_expand_data_with_subjects(
         #   train_x, train_y, train_subject_labels,
           # augment_data_eeg_bandwise, augment_ratio=0.6
        #)

        return train_x, train_y, test_x, test_y, test_id, train_subject_labels

    def train(self, only_test=False):

        train_x, train_y, test_x, test_y, test_id, train_subject_labels = self.get_source_data()
        subject_id = test_id
        #print("train_x.shape:", train_x.shape)
        #print("train_y.shape:", train_y.shape)
        #print("self.train_subject_labels.shape:", self.train_subject_labels.shape)

        #save_path_to_data = "/work/eee-zhangyf/xduer-SI-15600-5/"
        save_path_to_data = "E:/è¿…é›·ä¸‹è½½/xduer-SI-15600-5/"
        save_dir = os.path.join(save_path_to_data, 'GAM')
        os.makedirs(save_dir, exist_ok=True)

        all_conf_matrices = []
        results = []

        print(f"test for subject {subject_id}")
        train_x = torch.tensor(train_x, dtype=torch.float32).cuda()
        train_y = torch.tensor(train_y, dtype=torch.long).cuda()
        test_x = torch.tensor(test_x, dtype=torch.float32).cuda()
        test_y = torch.tensor(test_y, dtype=torch.long).cuda()
        train_subject_labels = torch.tensor(train_subject_labels, dtype=torch.long).cuda()

        self.model = EEGRegionModel(hidden_size=128, num_layers=1, num_classes=11, embed_size=128).cuda()
        self.model = nn.DataParallel(self.model)
        self.model = self.model.cuda()
        model_path = os.path.join(save_dir, f"subject_{subject_id}_best.pth")

        if not only_test:
            optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-5)

            best_val_acc = 0
            best_state = None
            train_accs = []
            val_accs = []
            val_checkpoints = []
            early_stopping = EarlyStopping(patience=60)  # ğŸ”¥æ¯”å¦‚ 20 æ¬¡éªŒè¯éƒ½æ²¡æå‡å°±åœæ­¢

            for episode in range(1, 14901):
                self.model.train()  # âœ… å¿…é¡»åŠ ï¼
                #x_ep, y_ep = create_diverse_episode(train_x, train_y, train_subject_labels, n_way=11, k_shot=3, q_query=6)
                x_ep, y_ep = create_episode_diverse_support_balanced_query(
                    train_x, train_y, train_subject_labels,
                    n_way=11, k_shot=3, q_query=4,
                )

                emb = self.model(x_ep)
                loss, acc, _, _ = dual_metric_prototypical_loss(emb, y_ep, n_support=3, alpha=0.5)

                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                if episode % 100 == 0:
                    print(f"[training for subject {subject_id}] Episode {episode}: loss={loss:.4f}, acc={acc:.4f}")
                    train_accs.append(acc.item())  # âœ… æ·»åŠ è¿™ä¸€è¡Œ\
            torch.save(self.model.state_dict(), model_path)

            # === æµ‹è¯•é˜¶æ®µ ===
        print(f"â–¶ Loading best model for subject {subject_id} for testing...")
        # self.model.load_state_dict(best_state)
        self.model.load_state_dict(torch.load(model_path))
        test_metrics = evaluate_protonet(self.model,
                                         test_x,
                                         test_y,
                                         save_dir=os.path.join(save_dir, f"subject_{subject_id}"),
                                         n_way=11, k_shot=3, q_query=4, n_episodes=1000)

        with open(os.path.join(save_dir, f"subject_{subject_id}_results.txt"), "w") as f:
            for k, v in test_metrics.items():
                if k != 'confusion_matrix':
                    f.write(f"{k}: {v:.4f}\\n")

        return test_metrics, save_dir


# ä¸»å‡½æ•°
def main():

    SUBJECTS = ['MM10', 'MM11', 'MM19', 'P02', 'MM05', 'MM16', 'MM21', 'MM18']
    PATH_TO_DATA = "D:\\Downloads\\KARA_ONE_Data\\ImaginedSpeechData\\"
    #PATH_TO_DATA = "/work/eee-zhangyf/xduann/KARA_ONE_Data/ImaginedSpeechData/"

    all_results = []
    all_conf_matrices = []

    for test_subject in SUBJECTS:
        print(f"\nğŸš€ Leave-One-Subject-Out: {test_subject} as test set")

        X_train_all, y_train_all, train_subject_labels_all = [], [], []
        X_test, y_test = None, None

        for subject in SUBJECTS:
            print(f"  Processing Subject: {subject}")
            df_raw = load_data(PATH_TO_DATA + subject + '/GAM', 'df_epochs_ica_no.pkl')
            X_raw, y_raw = extract_features_and_labels(df_raw)

            if subject == test_subject:
                X_test, y_test = X_raw, y_raw
            else:
                X_train_all.append(X_raw)
                y_train_all.append(y_raw)
                subj_index = SUBJECTS.index(subject)
                train_subject_labels_all.append(np.full(len(y_raw), subj_index))

        # æ‹¼æ¥è®­ç»ƒé›†
        X_train_all = np.concatenate(X_train_all, axis=0)
        y_train_all = np.concatenate(y_train_all, axis=0)
        train_subject_labels_all = np.concatenate(train_subject_labels_all, axis=0)

        #train_subject_labels_all = torch.tensor(train_subject_labels_all, dtype=torch.long).cuda()
        print(f"Train: {X_train_all.shape}, Test: {X_test.shape}")
        print("y_train_all shape:", y_train_all.shape)
        print("train_subject_labels_all shape:", train_subject_labels_all.shape)

        # === åˆ›å»º ExP å®ä¾‹ ===
        exp = ExP(X_train_all, y_train_all, X_test, y_test, test_id=test_subject, path_to_data=PATH_TO_DATA,
                  train_subject_labels=train_subject_labels_all)

        test_metrics, save_dir = exp.train()

        all_results.append(test_metrics)
        all_conf_matrices.append(test_metrics['confusion_matrix'])

    # æ±‡æ€»ç»“æœ
    avg_metrics = {}

    keys = ['accuracy', 'balanced_accuracy', 'kappa', 'recall', 'precision', 'f1']
    for key in keys:
        avg_metrics[key] = np.mean([res[key] for res in all_results])

    with open(os.path.join(save_dir, "average_results.txt"), "w") as f:
        for k, v in avg_metrics.items():
            f.write(f"Average {k}: {v:.4f}\n")

    avg_cm = np.mean(all_conf_matrices, axis=0)
    plt.figure(figsize=(10, 8))
    sns.heatmap(avg_cm, annot=True, fmt='.1f', cmap='RdPu', linewidths=0.3, linecolor='gray', square=True,
                cbar_kws={'label': 'Avg Count'})
    plt.title('Average Confusion Matrix Across Subjects', fontsize=16)
    plt.xlabel('Predicted Label', fontsize=12)
    plt.ylabel('True Label', fontsize=12)
    plt.xticks(fontsize=10)
    plt.yticks(fontsize=10)
    plt.tight_layout()
    plt.savefig(os.path.join(save_dir, "average_confusion_matrix.png"))
    plt.close()

    print("âœ… LOSO experiment complete. Results saved.")


if __name__ == "__main__":
    main()
